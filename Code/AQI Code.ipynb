{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51c33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#    These are standard python modules\n",
    "#\n",
    "#import json, time, urllib.parse\n",
    "import json, time\n",
    "#\n",
    "#    The 'requests' module is a distribution module for making web requests.\n",
    "#\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#\n",
    "#    This is the root of all AQS API URLs\n",
    "#\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#\n",
    "#    These are 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "#\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "#\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "# \n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",     \n",
    "    \"key\":        \"\",      \n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n",
    "\n",
    "\n",
    "USERNAME = \"prerit16@uw.edu\"\n",
    "APIKEY= 'baygoose33' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb1601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"AIRNOW MAPS\",\n",
      "        \"value_represented\": \"The parameters represented on AirNow maps (88101, 88502, and 44201)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"ALL\",\n",
      "        \"value_represented\": \"Select all Parameters Available\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"AQI POLLUTANTS\",\n",
      "        \"value_represented\": \"Pollutants that have an AQI Defined\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CORE_HAPS\",\n",
      "        \"value_represented\": \"Urban Air Toxic Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CRITERIA\",\n",
      "        \"value_represented\": \"Criteria Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CSN DART\",\n",
      "        \"value_represented\": \"List of CSN speciation parameters to populate the STI DART tool\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"FORECAST\",\n",
      "        \"value_represented\": \"Parameters routinely extracted by AirNow (STI)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"HAPS\",\n",
      "        \"value_represented\": \"Hazardous Air Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE CARBON\",\n",
      "        \"value_represented\": \"IMPROVE Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE_SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters Measured at IMPROVE sites\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"MET\",\n",
      "        \"value_represented\": \"Meteorological Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS CORE HAPS\",\n",
      "        \"value_represented\": \"The core list of toxics of interest to the NATTS program.\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS REQUIRED\",\n",
      "        \"value_represented\": \"Required compounds to be collected in the National Air Toxics Network\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS\",\n",
      "        \"value_represented\": \"Photochemical Assessment Monitoring System\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS_VOC\",\n",
      "        \"value_represented\": \"Volatile Organic Compound subset of the PAMS Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM COARSE\",\n",
      "        \"value_represented\": \"PM between 2.5 and 10 micrometers\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM10 SPECIATION\",\n",
      "        \"value_represented\": \"PM10 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 CONT NONREF\",\n",
      "        \"value_represented\": \"PM2.5 Continuous, Nonreference Methods\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 MASS/QA\",\n",
      "        \"value_represented\": \"PM2.5 Mass and QA Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SCHOOL AIR TOXICS\",\n",
      "        \"value_represented\": \"School Air Toxics Program Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CARBON\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CATION/ANION\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Cation/Anion Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION METALS\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Metal Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP CARBONYL\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program Carbonyls\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP VOC\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program VOCs\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"VOC\",\n",
      "        \"value_represented\": \"Volatile organic compounds\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors \n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "#\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL, \n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES, \n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "    \n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    \n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "\n",
    "#\n",
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e99946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
    "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
    "#   We'll use that to make another list request.\n",
    "#\n",
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e062a38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"42101\",\n",
      "        \"value_represented\": \"Carbon monoxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42401\",\n",
      "        \"value_represented\": \"Sulfur dioxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42602\",\n",
      "        \"value_represented\": \"Nitrogen dioxide (NO2)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"44201\",\n",
      "        \"value_represented\": \"Ozone\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"81102\",\n",
      "        \"value_represented\": \"PM10 Total 0-10um STP\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88101\",\n",
      "        \"value_represented\": \"PM2.5 - Local Conditions\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88502\",\n",
      "        \"value_represented\": \"Acceptable PM2.5 AQI & Speciation Mass\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0aabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "#   It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "#   all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "#\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\"\n",
    "#   \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f49869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   We'll use these two city locations in the examples below.\n",
    "#\n",
    "CITY_LOCATIONS = {\n",
    "    'Derby' :       {'city'   : 'Derby',\n",
    "                       'county' : 'Sedgwick',\n",
    "                       'state'  : 'Kansas',\n",
    "                       'fips'   : '20173',\n",
    "                       'latlon' : [37.552407, -97.261492] }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463913d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0001\",\n",
      "        \"value_represented\": \"PARK CITY\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0002\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0003\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0004\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0005\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0006\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0007\",\n",
      "        \"value_represented\": \"13TH & ST PAUL\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0008\",\n",
      "        \"value_represented\": \"WASH & SKINNER\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0009\",\n",
      "        \"value_represented\": \"PAWNEE & GLENN\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0010\",\n",
      "        \"value_represented\": \"WICHITA HD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0011\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0012\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0013\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0014\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0015\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0016\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0017\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0018\",\n",
      "        \"value_represented\": \"Sedgwick Ozone\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0080\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0081\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1001\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1002\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1003\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1004\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1011\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1012\",\n",
      "        \"value_represented\": \"HYDRAULIC\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1013\",\n",
      "        \"value_represented\": null\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1014\",\n",
      "        \"value_represented\": \"DOUGLAS & MAIN\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"5501\",\n",
      "        \"value_represented\": \"Colvin Elementary\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['Derby']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['Derby']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e67cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date. \n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL, \n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY, \n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "    \n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]            \n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']: \n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']: \n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']: \n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "        \n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c376c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This is a list of field names - data - that will be extracted from each record\n",
    "#\n",
    "EXTRACTION_FIELDS = ['sample_duration','observation_count','arithmetic_mean','aqi']\n",
    "\n",
    "#\n",
    "#    The function creates a summary record\n",
    "def extract_summary_from_response(r=None, fields=EXTRACTION_FIELDS):\n",
    "    ## the result will be structured around monitoring site, parameter, and then date\n",
    "    result = dict()\n",
    "    data = r[\"Data\"]\n",
    "    for record in data:\n",
    "        # make sure the record is set up\n",
    "        site = record['site_number']\n",
    "        param = record['parameter_code']\n",
    "        #date = record['date_local']    # this version keeps the respnse value YYYY-\n",
    "        date = record['date_local'].replace('-','') # this puts it in YYYYMMDD format\n",
    "        if site not in result:\n",
    "            result[site] = dict()\n",
    "            result[site]['local_site_name'] = record['local_site_name']\n",
    "            result[site]['site_address'] = record['site_address']\n",
    "            result[site]['state'] = record['state']\n",
    "            result[site]['county'] = record['county']\n",
    "            result[site]['city'] = record['city']\n",
    "            result[site]['pollutant_type'] = dict()\n",
    "        if param not in result[site]['pollutant_type']:\n",
    "            result[site]['pollutant_type'][param] = dict()\n",
    "            result[site]['pollutant_type'][param]['parameter_name'] = record['parameter']\n",
    "            result[site]['pollutant_type'][param]['units_of_measure'] = record['units_of_measure']\n",
    "            result[site]['pollutant_type'][param]['method'] = record['method']\n",
    "            result[site]['pollutant_type'][param]['data'] = dict()\n",
    "        if date not in result[site]['pollutant_type'][param]['data']:\n",
    "            result[site]['pollutant_type'][param]['data'][date] = list()\n",
    "        \n",
    "        # now extract the specified fields\n",
    "        extract = dict()\n",
    "        for k in fields:\n",
    "            if str(k) in record:\n",
    "                extract[str(k)] = record[k]\n",
    "            else:\n",
    "                # this makes sure we always have the requested fields, even if\n",
    "                # we have a missing value for a given day/month\n",
    "                extract[str(k)] = None\n",
    "        \n",
    "        # add this extraction to the list for the day\n",
    "        result[site]['pollutant_type'][param]['data'][date].append(extract)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e3dcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for 1963.\n",
      "No data available for 1964.\n",
      "No data available for 1965.\n",
      "No data available for 1966.\n",
      "No data available for 1967.\n",
      "No data available for 1968.\n",
      "No data available for 1969.\n",
      "No data available for 1970.\n",
      "No data available for 1971.\n",
      "No data available for 1972.\n",
      "No data available for 1973.\n",
      "No data available for 1974.\n",
      "No data available for 1975.\n",
      "No data available for 1976.\n",
      "No data available for 1977.\n",
      "No data available for 1978.\n",
      "No data available for 1979.\n",
      "No data available for 1980.\n",
      "No data available for 1981.\n",
      "No data available for 1982.\n",
      "No data available for 1983.\n",
      "No data available for 1984.\n",
      "No data available for 1985.\n",
      "Response for the particulate pollutants ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "request_data['state'] = CITY_LOCATIONS['Derby']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['Derby']['fips'][2:]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "all_particulate_data = []\n",
    "\n",
    "# Define the request template and base URL\n",
    "request_template = \"YOUR_REQUEST_TEMPLATE_HERE\"\n",
    "base_url = \"YOUR_BASE_URL_HERE\"\n",
    "\n",
    "# Define the years you want to retrieve data for\n",
    "start_year = 1963\n",
    "end_year = 2023\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Check the response and append data to the list\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        #all_gaseous_data.extend(gaseous_aqi['Data'])\n",
    "        extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "        #print(\"Summary of particulate extraction ...\")\n",
    "        #print(json.dumps(extract_gaseous,indent=4))\n",
    "        all_particulate_data.append(extract_particulate)\n",
    "        \n",
    "    elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data available for {year}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error in retrieving data for {year}.\")\n",
    "\n",
    "# Print or process the collected data\n",
    "print(\"Response for the particulate pollutants ...\")\n",
    "print(json.dumps(all_particulate_data, indent=4))\n",
    "\n",
    "# Now, the all_gaseous_data list contains data for each year from 1963 to 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9d07c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for the year : 1963.\n",
      "No data for the year : 1964.\n",
      "No data for the year : 1965.\n",
      "No data for the year : 1966.\n",
      "No data for the year : 1967.\n",
      "No data for the year : 1968.\n",
      "No data for the year : 1969.\n",
      "No data for the year : 1970.\n",
      "No data for the year : 1971.\n",
      "No data for the year : 1972.\n",
      "No data for the year : 1973.\n",
      "No data for the year : 1974.\n",
      "No data for the year : 1975.\n",
      "No data for the year : 1976.\n",
      "No data for the year : 1977.\n",
      "No data for the year : 1978.\n",
      "No data for the year : 1979.\n",
      "No data for the year : 1980.\n",
      "No data for the year : 1981.\n",
      "No data for the year : 1982.\n",
      "No data for the year : 1983.\n",
      "No data for the year : 1984.\n",
      "No data for the year : 1985.\n",
      "Fetched Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Stored as JSON\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "request_data['state'] = CITY_LOCATIONS['Derby']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['Derby']['fips'][2:]\n",
    "\n",
    "## Final List where all the data will be stored\n",
    "particulate_data = []\n",
    "# Years under consideration\n",
    "start_year = 1963\n",
    "end_year = 2023\n",
    "\n",
    "# Fetching Data for Every Year\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = str(year) + \"0101\"\n",
    "    end_date = str(year) + \"1231\"\n",
    "\n",
    "    # Creating template for the for the current year in the loop to fetch data\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Appending data to the list if status is Success\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        extract_particulate = extract_summary_from_response(particulate_aqi)\n",
    "        particulate_data.append(extract_particulate)\n",
    "    elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data for the year : {year}.\")\n",
    "    else:\n",
    "        print(f\"Error in retrieving data for the year : {year}.\")\n",
    "\n",
    "## Printing all data fetched\n",
    "print(\"Fetched Data\")\n",
    "print(json.dumps(particulate_data, indent=4))\n",
    "\n",
    "# Storing the result in a JSON\n",
    "with open(\"../Data/particulate_data.json\", 'w') as file:\n",
    "    json.dump(particulate_data, file, indent=4)\n",
    "print(\"Data Stored as JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7092c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c05821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the result in a JSON\n",
    "with open(\"../Data/particulate_data.json\", 'w') as file:\n",
    "    json.dump(all_particulate_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd82ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for 1964.\n",
      "No data available for 1965.\n",
      "No data available for 1966.\n",
      "No data available for 1967.\n",
      "Response for the gaseous pollutants ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['Derby']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['Derby']['fips'][2:]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "all_gaseous_data = []\n",
    "\n",
    "# Define the request template and base URL\n",
    "request_template = \"YOUR_REQUEST_TEMPLATE_HERE\"\n",
    "base_url = \"YOUR_BASE_URL_HERE\"\n",
    "\n",
    "# Define the years you want to retrieve data for\n",
    "start_year = 1963\n",
    "end_year = 2023\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Check the response and append data to the list\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        #all_gaseous_data.extend(gaseous_aqi['Data'])\n",
    "        extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "        #print(\"Summary of particulate extraction ...\")\n",
    "        #print(json.dumps(extract_gaseous,indent=4))\n",
    "        all_gaseous_data.append(extract_gaseous)\n",
    "        \n",
    "    elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data available for {year}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error in retrieving data for {year}.\")\n",
    "\n",
    "# Print or process the collected data\n",
    "print(\"Response for the gaseous pollutants ...\")\n",
    "print(json.dumps(all_gaseous_data, indent=4))\n",
    "\n",
    "# Now, the all_gaseous_data list contains data for each year from 1963 to 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a434525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for the year : 1964.\n",
      "No data for the year : 1965.\n",
      "No data for the year : 1966.\n",
      "No data for the year : 1967.\n",
      "Fetched Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Stored as JSON\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['Derby']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['Derby']['fips'][2:]\n",
    "\n",
    "## Final List where all the data will be stored\n",
    "gaseous_data = []\n",
    "\n",
    "# Years under consideration\n",
    "start_year = 1963\n",
    "end_year = 2023\n",
    "\n",
    "# Fetching Data for Every Year\n",
    "for year in range(start_year, end_year + 1):\n",
    "    begin_date = str(year) + \"0101\"\n",
    "    end_date = str(year) + \"1231\"\n",
    "    \n",
    "    # Creating template for the for the current year in the loop to fetch data\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Appending data to the list if status is Success\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        extract_gaseous = extract_summary_from_response(gaseous_aqi)\n",
    "        gaseous_data.append(extract_gaseous)\n",
    "        \n",
    "    elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data for the year : {year}.\")\n",
    "    else:\n",
    "        print(f\"Error in retrieving data for the year : {year}.\")\n",
    "\n",
    "## Printing all data fetched\n",
    "print(\"Fetched Data\")\n",
    "print(json.dumps(gaseous_data, indent=4))\n",
    "\n",
    "# Storing the result in a JSON\n",
    "with open(\"../Data/gaseous_data.json\", 'w') as file:\n",
    "    json.dump(gaseous_data, file, indent=4)\n",
    "print(\"Data Stored as JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd3f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a88010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file name\n",
    "output_file = \"../Data/gaseous_data.json\"\n",
    "\n",
    "# Write the JSON data to the text file with an indentation of 4\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(all_gaseous_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbfac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aqi(data, dynamic_keys=None):\n",
    "    if dynamic_keys is None:\n",
    "        dynamic_keys = []\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for key, value in data.items():\n",
    "        current_keys = dynamic_keys + [key]\n",
    "\n",
    "        if isinstance(value, dict):\n",
    "            extracted_data.extend(extract_aqi(value, current_keys))\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    aqi = item.get(\"aqi\")\n",
    "                    sample_duration = item.get(\"sample_duration\")\n",
    "                    if aqi is not None:\n",
    "                        extracted_data.append({\"keys\": current_keys,\"sample_duration\": sample_duration, \"aqi\": aqi})\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6783003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the extracted data\n",
    "extracted_data_gaseous = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for dataset in all_gaseous_data:\n",
    "    extracted_data_gaseous.extend(extract_aqi(dataset))\n",
    "\n",
    "# Initialize a list to store the extracted data\n",
    "extracted_data_particulate = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for dataset in all_particulate_data:\n",
    "    extracted_data_particulate.extend(extract_aqi(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58cbfb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gasesous_particulate(input_df):\n",
    "    processed_data = []\n",
    "    for entry in input_df:\n",
    "        keys = entry['keys']\n",
    "        date = keys[-1]\n",
    "        aqi = entry['aqi']\n",
    "        sample_duration = entry['sample_duration']\n",
    "        pollutant_type = keys[-3]\n",
    "        processed_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "daafe82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-08-12</td>\n",
       "      <td>48</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-08-18</td>\n",
       "      <td>25</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-08-24</td>\n",
       "      <td>30</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-08-30</td>\n",
       "      <td>28</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-09-05</td>\n",
       "      <td>30</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89105</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89106</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89107</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89108</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89109</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AQI Sample_Duration Pollutant_Type\n",
       "0     1986-08-12   48         24 HOUR          81102\n",
       "1     1986-08-18   25         24 HOUR          81102\n",
       "2     1986-08-24   30         24 HOUR          81102\n",
       "3     1986-08-30   28         24 HOUR          81102\n",
       "4     1986-09-05   30         24 HOUR          81102\n",
       "...          ...  ...             ...            ...\n",
       "89105 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89106 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89107 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89108 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89109 2023-06-30   47   24-HR BLK AVG          88101\n",
       "\n",
       "[89110 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant information and create a new list of dictionaries\n",
    "formatted_data = []\n",
    "\n",
    "for entry in extracted_data_particulate:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "# Create a DataFrame from the formatted data\n",
    "particulate_df = pd.DataFrame(formatted_data)\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "particulate_df['Date'] = pd.to_datetime(particulate_df['Date'], format='%Y%m%d')\n",
    "particulate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "757bbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aqi2(data, dynamic_keys=None):\n",
    "    if dynamic_keys is None:\n",
    "        dynamic_keys = []\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for key in data.keys():\n",
    "        current_keys = dynamic_keys + [key]\n",
    "        if isinstance(data[key], dict):\n",
    "            extracted_data.extend(extract_aqi2(data[key], current_keys))\n",
    "        elif isinstance(data[key], list):\n",
    "            for item in data[key]:\n",
    "                if isinstance(item, dict):\n",
    "                    aqi = item[\"aqi\"]\n",
    "                    sample_duration = item[\"sample_duration\"]\n",
    "                    if aqi is not None:\n",
    "                        extracted_data.append({\"keys\": current_keys,\"sample_duration\": sample_duration, \"aqi\": aqi})\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a385808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the extracted data\n",
    "extracted_data_gaseous = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for dataset in all_gaseous_data:\n",
    "    extracted_data_gaseous.extend(extract_aqi2(dataset))\n",
    "\n",
    "# Initialize a list to store the extracted data\n",
    "extracted_data_particulate = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for dataset in all_particulate_data:\n",
    "    extracted_data_particulate.extend(extract_aqi2(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b9152bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-08-12</td>\n",
       "      <td>48</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-08-18</td>\n",
       "      <td>25</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-08-24</td>\n",
       "      <td>30</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-08-30</td>\n",
       "      <td>28</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-09-05</td>\n",
       "      <td>30</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89105</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89106</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89107</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89108</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89109</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AQI Sample_Duration Pollutant_Type\n",
       "0     1986-08-12   48         24 HOUR          81102\n",
       "1     1986-08-18   25         24 HOUR          81102\n",
       "2     1986-08-24   30         24 HOUR          81102\n",
       "3     1986-08-30   28         24 HOUR          81102\n",
       "4     1986-09-05   30         24 HOUR          81102\n",
       "...          ...  ...             ...            ...\n",
       "89105 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89106 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89107 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89108 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89109 2023-06-30   47   24-HR BLK AVG          88101\n",
       "\n",
       "[89110 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant information and create a new list of dictionaries\n",
    "formatted_data = []\n",
    "\n",
    "for entry in extracted_data_particulate:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "# Create a DataFrame from the formatted data\n",
    "particulate_df = pd.DataFrame(formatted_data)\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "particulate_df['Date'] = pd.to_datetime(particulate_df['Date'], format='%Y%m%d')\n",
    "particulate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b092f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82978b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc22ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05c65c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986-08-12</td>\n",
       "      <td>48</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986-08-18</td>\n",
       "      <td>25</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-08-24</td>\n",
       "      <td>30</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986-08-30</td>\n",
       "      <td>28</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986-09-05</td>\n",
       "      <td>30</td>\n",
       "      <td>24 HOUR</td>\n",
       "      <td>81102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89105</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89106</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89107</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89108</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89109</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>47</td>\n",
       "      <td>24-HR BLK AVG</td>\n",
       "      <td>88101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  AQI Sample_Duration Pollutant_Type\n",
       "0     1986-08-12   48         24 HOUR          81102\n",
       "1     1986-08-18   25         24 HOUR          81102\n",
       "2     1986-08-24   30         24 HOUR          81102\n",
       "3     1986-08-30   28         24 HOUR          81102\n",
       "4     1986-09-05   30         24 HOUR          81102\n",
       "...          ...  ...             ...            ...\n",
       "89105 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89106 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89107 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89108 2023-06-30   47   24-HR BLK AVG          88101\n",
       "89109 2023-06-30   47   24-HR BLK AVG          88101\n",
       "\n",
       "[89110 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particulate_df = pd.DataFrame(process_gasesous_particulate(extracted_data_particulate))\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "particulate_df['Date'] = pd.to_datetime(particulate_df['Date'], format='%Y%m%d')\n",
    "particulate_df\n",
    "\n",
    "gaseous_df = pd.DataFrame(process_gasesous_particulate(extracted_data_gaseous))\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "gaseous_df['Date'] = pd.to_datetime(gaseous_df['Date'], format='%Y%m%d')\n",
    "gaseous_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab76d1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971-09-20</td>\n",
       "      <td>22</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971-09-22</td>\n",
       "      <td>26</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971-09-23</td>\n",
       "      <td>24</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971-09-24</td>\n",
       "      <td>35</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971-09-25</td>\n",
       "      <td>33</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168290</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>61</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168291</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>61</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168293</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168294</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168295 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  AQI          Sample_Duration Pollutant_Type\n",
       "0      1971-09-20   22    8-HR RUN AVG END HOUR          42101\n",
       "1      1971-09-22   26    8-HR RUN AVG END HOUR          42101\n",
       "2      1971-09-23   24    8-HR RUN AVG END HOUR          42101\n",
       "3      1971-09-24   35    8-HR RUN AVG END HOUR          42101\n",
       "4      1971-09-25   33    8-HR RUN AVG END HOUR          42101\n",
       "...           ...  ...                      ...            ...\n",
       "168290 2023-06-29   61  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168291 2023-06-29   61  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168292 2023-06-30   44  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168293 2023-06-30   44  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168294 2023-06-30   44  8-HR RUN AVG BEGIN HOUR          44201\n",
       "\n",
       "[168295 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant information and create a new list of dictionaries\n",
    "formatted_data = []\n",
    "\n",
    "for entry in extracted_data_gaseous:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "# Create a DataFrame from the formatted data\n",
    "gaseous_df = pd.DataFrame(formatted_data)\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "gaseous_df['Date'] = pd.to_datetime(gaseous_df['Date'], format='%Y%m%d')\n",
    "gaseous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "436fb0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AQI</th>\n",
       "      <th>Sample_Duration</th>\n",
       "      <th>Pollutant_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971-09-20</td>\n",
       "      <td>22</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971-09-22</td>\n",
       "      <td>26</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971-09-23</td>\n",
       "      <td>24</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1971-09-24</td>\n",
       "      <td>35</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971-09-25</td>\n",
       "      <td>33</td>\n",
       "      <td>8-HR RUN AVG END HOUR</td>\n",
       "      <td>42101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168290</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>61</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168291</th>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>61</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168293</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168294</th>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>8-HR RUN AVG BEGIN HOUR</td>\n",
       "      <td>44201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168295 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  AQI          Sample_Duration Pollutant_Type\n",
       "0      1971-09-20   22    8-HR RUN AVG END HOUR          42101\n",
       "1      1971-09-22   26    8-HR RUN AVG END HOUR          42101\n",
       "2      1971-09-23   24    8-HR RUN AVG END HOUR          42101\n",
       "3      1971-09-24   35    8-HR RUN AVG END HOUR          42101\n",
       "4      1971-09-25   33    8-HR RUN AVG END HOUR          42101\n",
       "...           ...  ...                      ...            ...\n",
       "168290 2023-06-29   61  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168291 2023-06-29   61  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168292 2023-06-30   44  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168293 2023-06-30   44  8-HR RUN AVG BEGIN HOUR          44201\n",
       "168294 2023-06-30   44  8-HR RUN AVG BEGIN HOUR          44201\n",
       "\n",
       "[168295 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaseous_df = pd.DataFrame(process_gasesous_particulate(extracted_data_gaseous))\n",
    "\n",
    "# Convert the 'Date' column to a datetime format\n",
    "gaseous_df['Date'] = pd.to_datetime(gaseous_df['Date'], format='%Y%m%d')\n",
    "gaseous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33431c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e0264e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaseous_df.to_csv(\"../Data/gaseous_aqi_data_processed.csv\")\n",
    "particulate_df.to_csv(\"../Data/particulate_aqi_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b86e56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "particulate_df_copy = particulate_df.copy()\n",
    "gaseous_df_copy = gaseous_df.copy()\n",
    "particulate_df_copy.drop(['Sample_Duration', 'Pollutant_Type'], axis=1, inplace=True)\n",
    "gaseous_df_copy.drop(['Sample_Duration', 'Pollutant_Type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c8f50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Date' and calculate the mean for each group\n",
    "part_avg_df = particulate_df_copy.groupby('Date').mean().reset_index(drop = False)\n",
    "gas_avg_df = gaseous_df_copy.groupby('Date').mean().reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98ee2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the year from the 'Date' column\n",
    "# gaseous_avg_df['Year'] = gaseous_avg_df['Date'].dt.year\n",
    "# particulate_avg_df['Year'] = particulate_avg_df['Date'].dt.year\n",
    "\n",
    "# Merge the DataFrames on 'Date' and take the maximum AQI or fill with values from either DataFrame\n",
    "merged_df = pd.merge(gas_avg_df, part_avg_df, on='Date', how='outer', suffixes=('_g', '_p'))\n",
    "merged_df['AQI'] = merged_df[['AQI_g', 'AQI_p']].max(axis=1)\n",
    "merged_df.drop(columns=['AQI_g', 'AQI_p'], inplace=True)\n",
    "# Extract the year from the 'Date' column\n",
    "merged_df['Year'] = merged_df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b8b468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1971</td>\n",
       "      <td>29.473214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972</td>\n",
       "      <td>25.860806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1973</td>\n",
       "      <td>26.414820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1974</td>\n",
       "      <td>47.145204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>42.049516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year        AQI\n",
       "0  1971  29.473214\n",
       "1  1972  25.860806\n",
       "2  1973  26.414820\n",
       "3  1974  47.145204\n",
       "4  1975  42.049516"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'Year' and calculate the mean AQI for each year\n",
    "aqi_df = merged_df.groupby('Year')['AQI'].mean().reset_index()\n",
    "aqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41153143",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_df.to_csv(\"../Data/final_aqi_each_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c6613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb6957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
